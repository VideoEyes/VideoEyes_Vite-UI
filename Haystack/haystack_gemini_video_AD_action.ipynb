{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator\n",
    "# import Part of Google Vertex AI\n",
    "from vertexai.generative_models import Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Schema to Parse the JSON Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, validator\n",
    "\n",
    "class audioDescription(BaseModel):\n",
    "    audioDescription: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = audioDescription.schema_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Component: OutputValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional, List\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "import re\n",
    "\n",
    "# Define the component input parameters\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    # Define the component output\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        # Try to parse the LLM's reply\n",
    "        try:\n",
    "            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', replies[0])\n",
    "            if json_match is None:\n",
    "                json_match = re.search(r'```python\\s*([\\s\\S]*?)\\s*```', replies[0])\n",
    "                if json_match is None:\n",
    "                    raise ValueError(\"No JSON block found in the LLM's reply\")\n",
    "            \n",
    "            output_dict = json.loads(json_match.group(1))\n",
    "            replies[0] = json_match.group(1)\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            \n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": replies}\n",
    "\n",
    "        # Handle invalid JSON or other errors\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_validator = OutputValidator(pydantic_model=audioDescription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "你是專業的口述影像稿生成器，參考以下影片\n",
    "僅依照提供的資料，創建一個50字以內的口述影像腳本JSON文件，儘量貼近原作品再現的原則。無須描述對話，其中包含一個繁體中文口述影像旁白腳本。內容應該是一個字符串。例如：\n",
    "{{schema}}\n",
    "僅使用提供的資料，不要添加任何其他資訊並確保您的答案符合格式要求，確保回覆是dict類型。\n",
    "{% if invalid_replies and error_message %}\n",
    "您已經在先前的嘗試中建立了以下輸出：{{invalid_replies}}\n",
    "但是，這不符合上面的格式要求並觸發了此 Python 異常：{{error_message}}\n",
    "更正輸出並重試。只需返回正確的輸出，無需任何額外的解釋。\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在prompt中加入影片\n",
    "@component\n",
    "class AddVideo2Prompt:\n",
    "    # [\n",
    "    #     Part.from_uri(\n",
    "    #         \"gs://gemini-ad-gen/AD001.mp4\", mime_type=\"video/mp4\"\n",
    "    #     ),\n",
    "    #     prompt\n",
    "    # ]\n",
    "    def __init__(self, prompt: str):\n",
    "        self.prompt = prompt\n",
    "\n",
    "    @component.output_types(prompt=list)\n",
    "    def run(self,schema: str , uri: str, invalid_replies: Optional[List[str]] = None, error_message: Optional[str] = None):\n",
    "        prompt = prompt_builder.run(schema=schema, invalid_replies=invalid_replies, error_message=error_message)\n",
    "        return {\"prompt\": [Part.from_uri(uri, mime_type=\"video/mp4\"),prompt[\"prompt\"]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_video_2_prompt = AddVideo2Prompt(prompt=prompt_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GeminiGenerator:\n",
    "    def __init__(self, project_id, location, model):\n",
    "        self.project_id = project_id\n",
    "        self.location = location\n",
    "        self.model = model\n",
    "    \n",
    "    @component.output_types(replies=List[str])\n",
    "    def run(self, prompt: List):\n",
    "        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)\n",
    "        return {\"replies\": generator.run(prompt)[\"replies\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_generator = GeminiGenerator(project_id=\"gemini-rain-py\", location=\"us-central1\", model=\"gemini-1.5-pro-preview-0514\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "@component\n",
    "class upload2GCS:\n",
    "    def __init__(self, bucket_name: str):\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    @component.output_types(uri=str)\n",
    "    def run(self, file_path: str):\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(self.bucket_name)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        return {\"uri\": f\"gs://{self.bucket_name}/{file_name}\"}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload2gcs = upload2GCS(bucket_name=\"gemini-ad-gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000017FD0277A90>\n",
       "🚅 Components\n",
       "  - upload2gcs: upload2GCS\n",
       "  - add_video: AddVideo2Prompt\n",
       "  - llm: GeminiGenerator\n",
       "  - output_validator: OutputValidator\n",
       "🛤️ Connections\n",
       "  - upload2gcs.uri -> add_video.uri (str)\n",
       "  - add_video.prompt -> llm.prompt (list)\n",
       "  - llm.replies -> output_validator.replies (List[str])\n",
       "  - output_validator.invalid_replies -> add_video.invalid_replies (Optional[List[str]])\n",
       "  - output_validator.error_message -> add_video.error_message (Optional[str])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "pipeline = Pipeline(max_loops_allowed=5)\n",
    "\n",
    "# Add components to your pipeline\n",
    "# pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=upload2gcs, name=\"upload2gcs\")\n",
    "pipeline.add_component(instance=add_video_2_prompt, name=\"add_video\")\n",
    "pipeline.add_component(instance=gemini_generator, name=\"llm\")\n",
    "pipeline.add_component(instance=output_validator, name=\"output_validator\")\n",
    "\n",
    "# Now, connect the components to each other\n",
    "# pipeline.connect(\"prompt_builder\", \"add_video\")\n",
    "pipeline.connect(\"upload2gcs\", \"add_video\")\n",
    "pipeline.connect(\"add_video.prompt\", \"llm\")\n",
    "# pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "pipeline.connect(\"llm\", \"output_validator\")\n",
    "# # If a component has more than one output or input, explicitly specify the connections:\n",
    "pipeline.connect(\"output_validator.invalid_replies\", \"add_video.invalid_replies\")\n",
    "pipeline.connect(\"output_validator.error_message\", \"add_video.error_message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(\"auto-correct-pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mOutputValidator at Iteration 1: Valid JSON from LLM - No need for looping: {\"audioDescription\": \"捷運站內人來人往，站務人員拿著無線電通話，並在閘門前蹲下和一名婦人說話。\"}\n"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\NUK\\GraduationProject\\UI\\VideoEyes_Vite-UI\\Haystack\\AD005.mp4\"\n",
    "result = pipeline.run({\n",
    "    \"upload2gcs\": { \"file_path\": path},\n",
    "    \"add_video\": {\"schema\": json_schema}\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audioDescription': '捷運站內人來人往，站務人員拿著無線電通話，並在閘門前蹲下和一名婦人說話。'}\n"
     ]
    }
   ],
   "source": [
    "valid_reply = result[\"output_validator\"][\"valid_replies\"][0]\n",
    "valid_json = json.loads(valid_reply)\n",
    "print(valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

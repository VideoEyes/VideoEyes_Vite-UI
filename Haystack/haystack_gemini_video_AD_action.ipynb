{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator\n",
    "# import Part of Google Vertex AI\n",
    "from vertexai.generative_models import Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Schema to Parse the JSON Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, validator\n",
    "\n",
    "class audioDescription(BaseModel):\n",
    "    audioDescription: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = audioDescription.schema_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Component: OutputValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional, List\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "import re\n",
    "\n",
    "# Define the component input parameters\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    # Define the component output\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        # Try to parse the LLM's reply\n",
    "        try:\n",
    "            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', replies[0])\n",
    "            if json_match is None:\n",
    "                json_match = re.search(r'```python\\s*([\\s\\S]*?)\\s*```', replies[0])\n",
    "                if json_match is None:\n",
    "                    raise ValueError(\"No JSON block found in the LLM's reply\")\n",
    "            \n",
    "            output_dict = json.loads(json_match.group(1))\n",
    "            replies[0] = json_match.group(1)\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            \n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": replies}\n",
    "\n",
    "        # Handle invalid JSON or other errors\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_validator = OutputValidator(pydantic_model=audioDescription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "ä½ æ˜¯å°ˆæ¥­çš„å£è¿°å½±åƒç¨¿ç”Ÿæˆå™¨ï¼Œåƒè€ƒä»¥ä¸‹å½±ç‰‡\n",
    "åƒ…ä¾ç…§æä¾›çš„è³‡æ–™ï¼Œå‰µå»ºä¸€å€‹50å­—ä»¥å…§çš„å£è¿°å½±åƒè…³æœ¬JSONæ–‡ä»¶ï¼Œå„˜é‡è²¼è¿‘åŸä½œå“å†ç¾çš„åŸå‰‡ã€‚ç„¡é ˆæè¿°å°è©±ï¼Œå…¶ä¸­åŒ…å«ä¸€å€‹ç¹é«”ä¸­æ–‡å£è¿°å½±åƒæ—ç™½è…³æœ¬ã€‚å…§å®¹æ‡‰è©²æ˜¯ä¸€å€‹å­—ç¬¦ä¸²ã€‚ä¾‹å¦‚ï¼š\n",
    "{{schema}}\n",
    "åƒ…ä½¿ç”¨æä¾›çš„è³‡æ–™ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–è³‡è¨Šä¸¦ç¢ºä¿æ‚¨çš„ç­”æ¡ˆç¬¦åˆæ ¼å¼è¦æ±‚ï¼Œç¢ºä¿å›è¦†æ˜¯dicté¡å‹ã€‚\n",
    "{% if invalid_replies and error_message %}\n",
    "æ‚¨å·²ç¶“åœ¨å…ˆå‰çš„å˜—è©¦ä¸­å»ºç«‹äº†ä»¥ä¸‹è¼¸å‡ºï¼š{{invalid_replies}}\n",
    "ä½†æ˜¯ï¼Œé€™ä¸ç¬¦åˆä¸Šé¢çš„æ ¼å¼è¦æ±‚ä¸¦è§¸ç™¼äº†æ­¤ Python ç•°å¸¸ï¼š{{error_message}}\n",
    "æ›´æ­£è¼¸å‡ºä¸¦é‡è©¦ã€‚åªéœ€è¿”å›æ­£ç¢ºçš„è¼¸å‡ºï¼Œç„¡éœ€ä»»ä½•é¡å¤–çš„è§£é‡‹ã€‚\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨promptä¸­åŠ å…¥å½±ç‰‡\n",
    "@component\n",
    "class AddVideo2Prompt:\n",
    "    # [\n",
    "    #     Part.from_uri(\n",
    "    #         \"gs://gemini-ad-gen/AD001.mp4\", mime_type=\"video/mp4\"\n",
    "    #     ),\n",
    "    #     prompt\n",
    "    # ]\n",
    "    def __init__(self, prompt: str):\n",
    "        self.prompt = prompt\n",
    "\n",
    "    @component.output_types(prompt=list)\n",
    "    def run(self,schema: str , uri: str, invalid_replies: Optional[List[str]] = None, error_message: Optional[str] = None):\n",
    "        prompt = prompt_builder.run(schema=schema, invalid_replies=invalid_replies, error_message=error_message)\n",
    "        return {\"prompt\": [Part.from_uri(uri, mime_type=\"video/mp4\"),prompt[\"prompt\"]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_video_2_prompt = AddVideo2Prompt(prompt=prompt_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GeminiGenerator:\n",
    "    def __init__(self, project_id, location, model):\n",
    "        self.project_id = project_id\n",
    "        self.location = location\n",
    "        self.model = model\n",
    "    \n",
    "    @component.output_types(replies=List[str])\n",
    "    def run(self, prompt: List):\n",
    "        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)\n",
    "        return {\"replies\": generator.run(prompt)[\"replies\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_generator = GeminiGenerator(project_id=\"gemini-rain-py\", location=\"us-central1\", model=\"gemini-1.5-pro-preview-0514\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "@component\n",
    "class upload2GCS:\n",
    "    def __init__(self, bucket_name: str):\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    @component.output_types(uri=str)\n",
    "    def run(self, file_path: str):\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(self.bucket_name)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        return {\"uri\": f\"gs://{self.bucket_name}/{file_name}\"}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload2gcs = upload2GCS(bucket_name=\"gemini-ad-gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000017FD0277A90>\n",
       "ğŸš… Components\n",
       "  - upload2gcs: upload2GCS\n",
       "  - add_video: AddVideo2Prompt\n",
       "  - llm: GeminiGenerator\n",
       "  - output_validator: OutputValidator\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - upload2gcs.uri -> add_video.uri (str)\n",
       "  - add_video.prompt -> llm.prompt (list)\n",
       "  - llm.replies -> output_validator.replies (List[str])\n",
       "  - output_validator.invalid_replies -> add_video.invalid_replies (Optional[List[str]])\n",
       "  - output_validator.error_message -> add_video.error_message (Optional[str])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "pipeline = Pipeline(max_loops_allowed=5)\n",
    "\n",
    "# Add components to your pipeline\n",
    "# pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=upload2gcs, name=\"upload2gcs\")\n",
    "pipeline.add_component(instance=add_video_2_prompt, name=\"add_video\")\n",
    "pipeline.add_component(instance=gemini_generator, name=\"llm\")\n",
    "pipeline.add_component(instance=output_validator, name=\"output_validator\")\n",
    "\n",
    "# Now, connect the components to each other\n",
    "# pipeline.connect(\"prompt_builder\", \"add_video\")\n",
    "pipeline.connect(\"upload2gcs\", \"add_video\")\n",
    "pipeline.connect(\"add_video.prompt\", \"llm\")\n",
    "# pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "pipeline.connect(\"llm\", \"output_validator\")\n",
    "# # If a component has more than one output or input, explicitly specify the connections:\n",
    "pipeline.connect(\"output_validator.invalid_replies\", \"add_video.invalid_replies\")\n",
    "pipeline.connect(\"output_validator.error_message\", \"add_video.error_message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(\"auto-correct-pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mOutputValidator at Iteration 1: Valid JSON from LLM - No need for looping: {\"audioDescription\": \"æ·é‹ç«™å…§äººä¾†äººå¾€ï¼Œç«™å‹™äººå“¡æ‹¿è‘—ç„¡ç·šé›»é€šè©±ï¼Œä¸¦åœ¨é–˜é–€å‰è¹²ä¸‹å’Œä¸€åå©¦äººèªªè©±ã€‚\"}\n"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\NUK\\GraduationProject\\UI\\VideoEyes_Vite-UI\\Haystack\\AD005.mp4\"\n",
    "result = pipeline.run({\n",
    "    \"upload2gcs\": { \"file_path\": path},\n",
    "    \"add_video\": {\"schema\": json_schema}\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audioDescription': 'æ·é‹ç«™å…§äººä¾†äººå¾€ï¼Œç«™å‹™äººå“¡æ‹¿è‘—ç„¡ç·šé›»é€šè©±ï¼Œä¸¦åœ¨é–˜é–€å‰è¹²ä¸‹å’Œä¸€åå©¦äººèªªè©±ã€‚'}\n"
     ]
    }
   ],
   "source": [
    "valid_reply = result[\"output_validator\"][\"valid_replies\"][0]\n",
    "valid_json = json.loads(valid_reply)\n",
    "print(valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

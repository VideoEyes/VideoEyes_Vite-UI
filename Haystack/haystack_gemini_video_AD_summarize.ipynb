{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-vertex-haystack in d:\\anaconda3\\envs\\ai\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform>=1.38 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-vertex-haystack) (1.47.0)\n",
      "Requirement already satisfied: haystack-ai in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-vertex-haystack) (2.4.0rc0)\n",
      "Requirement already satisfied: pyarrow>3 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-vertex-haystack) (16.1.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (2.15.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (2.26.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (4.25.2)\n",
      "Requirement already satisfied: packaging>=14.3 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (3.16.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (1.11.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (2.0.2)\n",
      "Requirement already satisfied: pydantic<3 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (1.10.12)\n",
      "Requirement already satisfied: docstring-parser<1 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-cloud-aiplatform>=1.38->google-vertex-haystack) (0.16)\n",
      "Requirement already satisfied: numpy>=1.16.6 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from pyarrow>3->google-vertex-haystack) (1.26.4)\n",
      "Requirement already satisfied: haystack-experimental in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (0.1.0)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (3.1.2)\n",
      "Requirement already satisfied: lazy-imports in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (10.3.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (2.8.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (1.30.1)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (2.0.3)\n",
      "Requirement already satisfied: posthog in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (6.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (8.2.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from haystack-ai->google-vertex-haystack) (4.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform>=1.38->google-vertex-haystack) (1.62.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform>=1.38->google-vertex-haystack) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform>=1.38->google-vertex-haystack) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform>=1.38->google-vertex-haystack) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform>=1.38->google-vertex-haystack) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform>=1.38->google-vertex-haystack) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.38->google-vertex-haystack) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.38->google-vertex-haystack) (2.7.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform>=1.38->google-vertex-haystack) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38->google-vertex-haystack) (1.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from openai>=1.1.0->haystack-ai->google-vertex-haystack) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from openai>=1.1.0->haystack-ai->google-vertex-haystack) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from openai>=1.1.0->haystack-ai->google-vertex-haystack) (0.24.1)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from openai>=1.1.0->haystack-ai->google-vertex-haystack) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from python-dateutil->haystack-ai->google-vertex-haystack) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->haystack-ai->google-vertex-haystack) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->haystack-ai->google-vertex-haystack) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->haystack-ai->google-vertex-haystack) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->haystack-ai->google-vertex-haystack) (2023.11.17)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from tqdm->haystack-ai->google-vertex-haystack) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from jinja2->haystack-ai->google-vertex-haystack) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from pandas->haystack-ai->google-vertex-haystack) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from pandas->haystack-ai->google-vertex-haystack) (2023.3)\n",
      "Requirement already satisfied: monotonic>=1.5 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from posthog->haystack-ai->google-vertex-haystack) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from posthog->haystack-ai->google-vertex-haystack) (2.2.1)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai->google-vertex-haystack) (0.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform>=1.38->google-vertex-haystack) (0.5.0)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in d:\\anaconda3\\envs\\ai\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai->google-vertex-haystack) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "# %pip install haystack-ai\n",
    "%pip install google-vertex-haystack\n",
    "%pip install git+https://github.com/deepset-ai/haystack.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.generators.google_vertex import VertexAIGeminiGenerator\n",
    "# import Part of Google Vertex AI\n",
    "from vertexai.generative_models import Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Schema to Parse the JSON Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, validator\n",
    "\n",
    "class audioDescription(BaseModel):\n",
    "    Audiodescription: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = audioDescription.schema_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class videoSummary(BaseModel):\n",
    "    who: str\n",
    "    what: str\n",
    "    when: str\n",
    "    where: str\n",
    "    how: str\n",
    "    why: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_schema = videoSummary.schema_json(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Component: OutputValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional, List\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "import re\n",
    "\n",
    "# Define the component input parameters\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    # Define the component output\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        # Try to parse the LLM's reply\n",
    "        try:\n",
    "            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', replies[0])\n",
    "            if json_match is None:\n",
    "                json_match = re.search(r'```python\\s*([\\s\\S]*?)\\s*```', replies[0])\n",
    "                if json_match is None:\n",
    "                    raise ValueError(\"No JSON block found in the LLM's reply\")\n",
    "            \n",
    "            output_dict = json.loads(json_match.group(1))\n",
    "            replies[0] = json_match.group(1)\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            \n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": replies}\n",
    "\n",
    "        # Handle invalid JSON or other errors\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_validator = OutputValidator(pydantic_model=audioDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_validator = OutputValidator(pydantic_model=videoSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "影片摘要:\n",
    "{{ summary }}\n",
    "\n",
    "你是專業的口述影像稿生成器，參考影片及影片摘要。\n",
    "僅依照提供的資料，創建一個50字以內的口述影像腳本JSON文件，儘量貼近原作品再現的原則，著重於劇情相關的畫面描述。無須描述對話，其中包含一個繁體中文口述影像旁白腳本。內容應該是一個字符串。例如：\n",
    "{{schema}}\n",
    "僅使用提供的資料，不要添加任何其他資訊並確保您的答案符合格式要求，確保回覆是dict類型。\n",
    "{% if invalid_replies and error_message %}\n",
    "您已經在先前的嘗試中建立了以下輸出：{{invalid_replies}}\n",
    "但是，這不符合上面的格式要求並觸發了此 Python 異常：{{error_message}}\n",
    "更正輸出並重試。只需返回正確的輸出，無需任何額外的解釋。\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"\n",
    "用 who、what、when、where、what、how、why 摘要以下影片\n",
    "僅依照提供的資料，創建一個JSON文件，其中包含who、what、when、where、what、how、why 字段。內容應該是一個字符串。例如：\n",
    "{{schema}}\n",
    "僅使用提供的資料，不要添加任何其他資訊並確保您的答案符合格式要求，確保回覆是dict類型。\n",
    "{% if invalid_replies and error_message %}\n",
    "您已經在先前的嘗試中建立了以下輸出：{{invalid_replies}}\n",
    "但是，這不符合上面的格式要求並觸發了此 Python 異常：{{error_message}}\n",
    "更正輸出並重試。只需返回正確的輸出，無需任何額外的解釋。\n",
    "{% endif %}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt_builder = PromptBuilder(template=summary_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在prompt中加入影片\n",
    "@component\n",
    "class AddVideo2Prompt:\n",
    "    # [\n",
    "    #     Part.from_uri(\n",
    "    #         \"gs://gemini-ad-gen/AD001.mp4\", mime_type=\"video/mp4\"\n",
    "    #     ),\n",
    "    #     prompt\n",
    "    # ]\n",
    "\n",
    "    @component.output_types(prompt=list)\n",
    "    def run(self, uri: str, prompt: str):\n",
    "        return {\"prompt\": [Part.from_uri(uri, mime_type=\"video/mp4\"),prompt]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_video_2_prompt = AddVideo2Prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_video_2_summary_prompt = AddVideo2Prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GeminiGenerator:\n",
    "    def __init__(self, project_id, location, model):\n",
    "        self.project_id = project_id\n",
    "        self.location = location\n",
    "        self.model = model\n",
    "    \n",
    "    @component.output_types(replies=List[str])\n",
    "    def run(self, prompt: List):\n",
    "        generator = VertexAIGeminiGenerator(project_id=self.project_id, location=self.location, model=self.model)\n",
    "        return {\"replies\": generator.run(prompt)[\"replies\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_generator = GeminiGenerator(project_id=\"gemini-rain-py\", location=\"us-central1\", model=\"gemini-1.5-pro-preview-0514\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_gemini_generator = GeminiGenerator(project_id=\"gemini-rain-py\", location=\"us-central1\", model=\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "@component\n",
    "class upload2GCS:\n",
    "    def __init__(self, bucket_name: str):\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    @component.output_types(uri=str)\n",
    "    def run(self, file_path: str):\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(self.bucket_name)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        return {\"uri\": f\"gs://{self.bucket_name}/{file_name}\"}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload2gcs = upload2GCS(bucket_name=\"gemini-ad-gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x000002F19DF5CE10>\n",
       "🚅 Components\n",
       "  - upload2gcs: upload2GCS\n",
       "  - summary_prompt_builder: PromptBuilder\n",
       "  - add_video_2_summary_prompt: AddVideo2Prompt\n",
       "  - summary_generator: GeminiGenerator\n",
       "  - summary_validator: OutputValidator\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - add_video: AddVideo2Prompt\n",
       "  - llm: GeminiGenerator\n",
       "  - output_validator: OutputValidator\n",
       "🛤️ Connections\n",
       "  - upload2gcs.uri -> add_video.uri (str)\n",
       "  - upload2gcs.uri -> add_video_2_summary_prompt.uri (str)\n",
       "  - summary_prompt_builder.prompt -> add_video_2_summary_prompt.prompt (str)\n",
       "  - add_video_2_summary_prompt.prompt -> summary_generator.prompt (list)\n",
       "  - summary_generator.replies -> summary_validator.replies (List[str])\n",
       "  - summary_validator.valid_replies -> prompt_builder.summary (List[str])\n",
       "  - summary_validator.invalid_replies -> summary_prompt_builder.invalid_replies (Optional[List[str]])\n",
       "  - summary_validator.error_message -> summary_prompt_builder.error_message (Optional[str])\n",
       "  - prompt_builder.prompt -> add_video.prompt (str)\n",
       "  - add_video.prompt -> llm.prompt (list)\n",
       "  - llm.replies -> output_validator.replies (List[str])\n",
       "  - output_validator.invalid_replies -> prompt_builder.invalid_replies (Optional[List[str]])\n",
       "  - output_validator.error_message -> prompt_builder.error_message (Optional[str])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "pipeline = Pipeline(max_loops_allowed=5)\n",
    "\n",
    "# Add components to your pipeline\n",
    "pipeline.add_component(instance=upload2gcs, name=\"upload2gcs\")\n",
    "pipeline.add_component(instance=summary_prompt_builder, name=\"summary_prompt_builder\")\n",
    "pipeline.add_component(instance=add_video_2_summary_prompt, name=\"add_video_2_summary_prompt\")\n",
    "pipeline.add_component(instance=summary_gemini_generator, name=\"summary_generator\")\n",
    "pipeline.add_component(instance=summary_validator, name=\"summary_validator\")\n",
    "pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=add_video_2_prompt, name=\"add_video\")\n",
    "pipeline.add_component(instance=gemini_generator, name=\"llm\")\n",
    "pipeline.add_component(instance=output_validator, name=\"output_validator\")\n",
    "\n",
    "# Now, connect the components to each other\n",
    "pipeline.connect(\"upload2gcs\", \"add_video\")\n",
    "pipeline.connect(\"upload2gcs\", \"add_video_2_summary_prompt\")\n",
    "pipeline.connect(\"summary_prompt_builder\", \"add_video_2_summary_prompt\")\n",
    "pipeline.connect(\"add_video_2_summary_prompt\", \"summary_generator\")\n",
    "pipeline.connect(\"summary_generator\", \"summary_validator\")\n",
    "pipeline.connect(\"summary_validator.valid_replies\", \"prompt_builder.summary\")\n",
    "pipeline.connect(\"summary_validator.invalid_replies\", \"summary_prompt_builder\")\n",
    "pipeline.connect(\"summary_validator.error_message\", \"summary_prompt_builder\")\n",
    "pipeline.connect(\"prompt_builder\", \"add_video\")\n",
    "pipeline.connect(\"add_video.prompt\", \"llm\")\n",
    "pipeline.connect(\"llm\", \"output_validator\")\n",
    "# # If a component has more than one output or input, explicitly specify the connections:\n",
    "pipeline.connect(\"output_validator.invalid_replies\", \"prompt_builder.invalid_replies\")\n",
    "pipeline.connect(\"output_validator.error_message\", \"prompt_builder.error_message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(\"auto-correct-pipeline_2_layer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mOutputValidator at Iteration 3: Valid JSON from LLM - No need for looping: {\n",
      "  \"who\": \"A security guard\",\n",
      "  \"what\": \"searching for a missing child in a subway station\",\n",
      "  \"when\": \"not specified\",\n",
      "  \"where\": \"in a subway station\",\n",
      "  \"how\": \"asking passengers and checking security cameras\",\n",
      "  \"why\": \"to find the missing child\"\n",
      "}\n",
      "\u001b[31mOutputValidator at Iteration 4: Invalid JSON from LLM - Let's try again.\n",
      "Output from LLM:\n",
      " {\"audioDescription\": {\"Audiodescription\": \"一名保安人員，正於捷運站內協尋一名走失兒童，他詢問乘客並查看監視器畫面\"}} \n",
      "Error from OutputValidator: 1 validation error for audioDescription\n",
      "audioDescription\n",
      "  str type expected (type=type_error.str)\n",
      "\u001b[31mOutputValidator at Iteration 5: Invalid JSON from LLM - Let's try again.\n",
      "Output from LLM:\n",
      " {\"audioDescription\": {\"Audiodescription\": \"捷運站內，一名保安人員手持無線電通話，神色焦急地搜尋著。另一名女保安彎腰詢問一名婦人，月台上的乘客來來往往。\"}} \n",
      "Error from OutputValidator: 1 validation error for audioDescription\n",
      "audioDescription\n",
      "  str type expected (type=type_error.str)\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:79\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\grpc\\_channel.py:1160\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1154\u001b[0m (\n\u001b[0;32m   1155\u001b[0m     state,\n\u001b[0;32m   1156\u001b[0m     call,\n\u001b[0;32m   1157\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1158\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1159\u001b[0m )\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\grpc\\_channel.py:1003\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.42.234:443 {created_time:\"2024-07-26T15:23:39.9703368+00:00\", grpc_status:8, grpc_message:\"Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNUK\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGraduationProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVideoEyes_Vite-UI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHaystack\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAD005.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mrun({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupload2gcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: path},\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_prompt_builder\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m: summary_schema},\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_builder\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m: json_schema}\n\u001b[0;32m      6\u001b[0m })\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\haystack\\core\\pipeline\\pipeline.py:231\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, data, debug, include_outputs_from)\u001b[0m\n\u001b[0;32m    228\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum loops count (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_loops_allowed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exceeded for component \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineMaxLoops(msg)\n\u001b[1;32m--> 231\u001b[0m res: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_component(name, components_inputs[name])\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m include_outputs_from:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# Deepcopy the outputs to prevent downstream nodes from modifying them\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# We don't care about loops - Always store the last output.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     extra_outputs[name] \u001b[38;5;241m=\u001b[39m deepcopy(res)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\haystack\\core\\pipeline\\pipeline.py:67\u001b[0m, in \u001b[0;36mPipeline._run_component\u001b[1;34m(self, name, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m span\u001b[38;5;241m.\u001b[39mset_content_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaystack.component.input\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[0;32m     66\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning component \u001b[39m\u001b[38;5;132;01m{component_name}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, component_name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m---> 67\u001b[0m res: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# After a Component that has variadic inputs is run, we need to reset the variadic inputs that were consumed\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m, in \u001b[0;36mGeminiGenerator.run\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;129m@component\u001b[39m\u001b[38;5;241m.\u001b[39moutput_types(replies\u001b[38;5;241m=\u001b[39mList[\u001b[38;5;28mstr\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: List):\n\u001b[0;32m     10\u001b[0m     generator \u001b[38;5;241m=\u001b[39m VertexAIGeminiGenerator(project_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_id, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplies\u001b[39m\u001b[38;5;124m\"\u001b[39m: generator\u001b[38;5;241m.\u001b[39mrun(prompt)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplies\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\haystack_integrations\\components\\generators\\google_vertex\\gemini.py:190\u001b[0m, in \u001b[0;36mVertexAIGeminiGenerator.run\u001b[1;34m(self, parts)\u001b[0m\n\u001b[0;32m    187\u001b[0m converted_parts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_part(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parts]\n\u001b[0;32m    189\u001b[0m contents \u001b[38;5;241m=\u001b[39m [Content(parts\u001b[38;5;241m=\u001b[39mconverted_parts, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m--> 190\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    191\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    192\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generation_config,\n\u001b[0;32m    193\u001b[0m     safety_settings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safety_settings,\n\u001b[0;32m    194\u001b[0m     tools\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tools,\n\u001b[0;32m    195\u001b[0m )\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mstart_chat()\n\u001b[0;32m    197\u001b[0m replies \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:405\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config, stream)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[0;32m    398\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    399\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    402\u001b[0m         tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[0;32m    403\u001b[0m     )\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[0;32m    406\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    407\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m    408\u001b[0m         safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[0;32m    409\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m    410\u001b[0m         tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[0;32m    411\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:494\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    487\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m    488\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    489\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m     tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[0;32m    493\u001b[0m )\n\u001b[1;32m--> 494\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_client\u001b[38;5;241m.\u001b[39mgenerate_content(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\prediction_service\\client.py:2102\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   2101\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 2102\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m   2103\u001b[0m     request,\n\u001b[0;32m   2104\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m   2105\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   2106\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m   2107\u001b[0m )\n\u001b[0;32m   2109\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\AI\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:81\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai."
     ]
    }
   ],
   "source": [
    "path = r\"D:\\NUK\\GraduationProject\\UI\\VideoEyes_Vite-UI\\Haystack\\AD005.mp4\"\n",
    "result = pipeline.run({\n",
    "    \"upload2gcs\": { \"file_path\": path},\n",
    "    \"summary_prompt_builder\": {\"schema\": summary_schema},\n",
    "    \"prompt_builder\": {\"schema\": json_schema}\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audioDescription': '一名保安人員在車站月台和閘門搜尋走失兒童。'}\n"
     ]
    }
   ],
   "source": [
    "valid_reply = result[\"output_validator\"][\"valid_replies\"][0]\n",
    "valid_json = json.loads(valid_reply)\n",
    "print(valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
